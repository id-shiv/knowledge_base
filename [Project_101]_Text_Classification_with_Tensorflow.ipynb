{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[Project 101] Text Classification with Tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMIYa6x8Nm3XMuuVlQM/2w7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/id-shiv/project_notebooks/blob/master/%5BProject_101%5D_Text_Classification_with_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k47_sbNEN6QF",
        "colab_type": "text"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSQyMx1RLrFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQeFGxzDN8fX",
        "colab_type": "text"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUs6LHKRa2B1",
        "colab_type": "text"
      },
      "source": [
        "Data is a corpus of movie reviews from keras dataset named imdb\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuL5vOrXNqJV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = keras.datasets.imdb\n",
        "(train_data, train_labels), (test_data, test_labels) = data.load_data(num_words=10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzZdqslHN-Md",
        "colab_type": "text"
      },
      "source": [
        "## View Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81cGJ6tMOAjF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index = data.get_word_index()\n",
        "word_index = {word: index+3 for word, index in word_index.items()}\n",
        "word_index[\"<PAD>\"] = 0  # Used to replace words that are outside the set limit of feature count\n",
        "word_index[\"<START>\"] = 1  # Used to indicate the start of the review\n",
        "word_index[\"<UNKNOWN>\"] = 2. # Used to indicate words that are not in word_index (since num_words=10000)\n",
        "word_index[\"<UNUSED>\"] = 3\n",
        "reverse_word_index = {index: word for word, index in word_index.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqgdQiFDWL3e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_review(review):\n",
        "  return \" \".join([reverse_word_index.get(i, '?') for i in review])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2-La9DwWg5b",
        "colab_type": "code",
        "outputId": "e32af284-5427-4ade-bde4-bb09279c09de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "decode_review(test_data[2])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<START> many animation buffs consider <UNKNOWN> <UNKNOWN> the great forgotten genius of one special branch of the art puppet animation which he invented almost single <UNKNOWN> and as it happened almost accidentally as a young man <UNKNOWN> was more interested in <UNKNOWN> than the cinema but his <UNKNOWN> attempt to film two <UNKNOWN> <UNKNOWN> fighting led to an unexpected breakthrough in film making when he realized he could <UNKNOWN> movement by <UNKNOWN> beetle <UNKNOWN> and <UNKNOWN> them one frame at a time this discovery led to the production of amazingly elaborate classic short the <UNKNOWN> revenge which he made in russia in <UNKNOWN> at a time when motion picture animation of all sorts was in its <UNKNOWN> br br the political <UNKNOWN> of the russian revolution caused <UNKNOWN> to move to paris where one of his first productions <UNKNOWN> was a dark political satire <UNKNOWN> known as <UNKNOWN> or the <UNKNOWN> who wanted a king a strain of black comedy can be found in almost all of films but here it is very dark indeed aimed more at grown ups who can appreciate the satirical aspects than children who would most likely find the climax <UNKNOWN> i'm middle aged and found it pretty <UNKNOWN> myself and indeed <UNKNOWN> of the film intended for english speaking viewers of the 1920s were given title cards filled with <UNKNOWN> and <UNKNOWN> in order to help <UNKNOWN> the sharp <UNKNOWN> of the finale br br our tale is set in a swamp the <UNKNOWN> <UNKNOWN> where the citizens are unhappy with their government and have called a special session to see what they can do to improve matters they decide to <UNKNOWN> <UNKNOWN> for a king the crowds are <UNKNOWN> animated in this opening sequence it couldn't have been easy to make so many frog puppets look alive simultaneously while <UNKNOWN> for his part is depicted as a <UNKNOWN> white <UNKNOWN> guy in the clouds who looks like he'd rather be taking a <UNKNOWN> when <UNKNOWN> sends them a tree like god who regards them the <UNKNOWN> decide that this is no improvement and demand a different king irritated <UNKNOWN> sends them a <UNKNOWN> br br delighted with this <UNKNOWN> looking new king who towers above them the <UNKNOWN> welcome him with a <UNKNOWN> of <UNKNOWN> dressed <UNKNOWN> the mayor steps forward to hand him the key to the <UNKNOWN> as <UNKNOWN> cameras record the event to everyone's horror the <UNKNOWN> promptly eats the mayor and then goes on a merry rampage <UNKNOWN> citizens at random a title card <UNKNOWN> reads news of the king's <UNKNOWN> throughout the kingdom when the now terrified <UNKNOWN> once more <UNKNOWN> <UNKNOWN> for help he loses his temper and <UNKNOWN> their community with lightning <UNKNOWN> the moral of our story delivered by a hapless frog just before he is eaten is let well enough alone br br considering the time period when this startling little film was made and considering the fact that it was made by a russian <UNKNOWN> at the height of that <UNKNOWN> country's civil war it would be easy to see this as a <UNKNOWN> about those events <UNKNOWN> may or may not have had <UNKNOWN> turmoil in mind when he made <UNKNOWN> but whatever <UNKNOWN> his choice of material the film stands as a <UNKNOWN> tale of universal <UNKNOWN> <UNKNOWN> could be the soviet union italy germany or japan in the 1930s or any country of any era that lets its guard down and is overwhelmed by <UNKNOWN> it's a fascinating film even a charming one in its macabre way but its message is no joke\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hkYkImzX-FT",
        "colab_type": "text"
      },
      "source": [
        "## Prepare Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5jrdr9bZBor",
        "colab_type": "text"
      },
      "source": [
        "### Feature consistency"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzwFbDlRYQzq",
        "colab_type": "text"
      },
      "source": [
        "Limit the number of words in a review to 250 (needed to know number of features i.e. number of neurons in input layer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTbk_5B-YALq",
        "colab_type": "code",
        "outputId": "4b332a08-9bed-4a1b-f8ef-4a13f4a16335",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_data = keras.preprocessing.sequence.pad_sequences(train_data, \n",
        "                                                        value=word_index[\"<PAD>\"],\n",
        "                                                        padding='post',\n",
        "                                                        maxlen=256)\n",
        "test_data = keras.preprocessing.sequence.pad_sequences(test_data, \n",
        "                                                        value=word_index[\"<PAD>\"],\n",
        "                                                        padding='post',\n",
        "                                                        maxlen=256)\n",
        "print(f'Length of Training Data : {len(train_data)}'\n",
        "      f'\\nLength of Test Data : {len(test_data)}')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of Training Data : 25000\n",
            "Length of Test Data : 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTFeDvpgZG4s",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fl2NDVhTaXid",
        "colab_type": "text"
      },
      "source": [
        "* Embedding : Create word vector for each word (10000 vectors in below example). Angle between each vector indicates similarity.  \n",
        "Set 16 dimensions to the vector in below example.\n",
        "* Global Average Pooling 1D : Scale down 16 dimentions (co-effecients) to 1 demention for easier compute.\n",
        "* Output : need 1 neuron to indicate 0 or 1 (good or bad). Sigmoid suits well for boolean.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPrtylRjZH5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(10000, 16))\n",
        "model.add(keras.layers.GlobalAveragePooling1D())\n",
        "model.add(keras.layers.Dense(16, activation='relu'))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKTLZ6SZUlgX",
        "colab_type": "text"
      },
      "source": [
        "## Compile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyAQl6mKUl48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIaF1PbOU28q",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtPB8FduV8tI",
        "colab_type": "text"
      },
      "source": [
        "Batch size : How many review to be loaded at once"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fx99xQpNU3GA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4d48bfb3-31d7-4067-800e-b99d5c0d1160"
      },
      "source": [
        "x_val = train_data[:10000]\n",
        "x_train = train_data[10000:]\n",
        "\n",
        "y_val = train_labels[:10000]\n",
        "y_train = train_labels[10000:]\n",
        "\n",
        "model.fit(x_train, y_train, epochs=40, batch_size=52, \n",
        "                          validation_data=(x_val, y_val), verbose=1)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15000 samples, validate on 10000 samples\n",
            "Epoch 1/40\n",
            "15000/15000 [==============================] - 2s 145us/sample - loss: 0.6556 - acc: 0.6991 - val_loss: 0.5561 - val_acc: 0.7925\n",
            "Epoch 2/40\n",
            "15000/15000 [==============================] - 2s 132us/sample - loss: 0.4194 - acc: 0.8525 - val_loss: 0.3513 - val_acc: 0.8652\n",
            "Epoch 3/40\n",
            "15000/15000 [==============================] - 2s 137us/sample - loss: 0.2839 - acc: 0.8947 - val_loss: 0.3048 - val_acc: 0.8732\n",
            "Epoch 4/40\n",
            "15000/15000 [==============================] - 2s 134us/sample - loss: 0.2280 - acc: 0.9145 - val_loss: 0.2835 - val_acc: 0.8852\n",
            "Epoch 5/40\n",
            "15000/15000 [==============================] - 2s 135us/sample - loss: 0.1900 - acc: 0.9331 - val_loss: 0.2787 - val_acc: 0.8880\n",
            "Epoch 6/40\n",
            "15000/15000 [==============================] - 2s 125us/sample - loss: 0.1616 - acc: 0.9446 - val_loss: 0.2825 - val_acc: 0.8871\n",
            "Epoch 7/40\n",
            "15000/15000 [==============================] - 2s 128us/sample - loss: 0.1397 - acc: 0.9551 - val_loss: 0.2917 - val_acc: 0.8862\n",
            "Epoch 8/40\n",
            "15000/15000 [==============================] - 2s 135us/sample - loss: 0.1198 - acc: 0.9617 - val_loss: 0.3013 - val_acc: 0.8864\n",
            "Epoch 9/40\n",
            "15000/15000 [==============================] - 2s 133us/sample - loss: 0.1027 - acc: 0.9694 - val_loss: 0.3175 - val_acc: 0.8837\n",
            "Epoch 10/40\n",
            "15000/15000 [==============================] - 2s 133us/sample - loss: 0.0896 - acc: 0.9744 - val_loss: 0.3318 - val_acc: 0.8806\n",
            "Epoch 11/40\n",
            "15000/15000 [==============================] - 2s 125us/sample - loss: 0.0767 - acc: 0.9802 - val_loss: 0.3500 - val_acc: 0.8796\n",
            "Epoch 12/40\n",
            "15000/15000 [==============================] - 2s 126us/sample - loss: 0.0663 - acc: 0.9850 - val_loss: 0.3698 - val_acc: 0.8782\n",
            "Epoch 13/40\n",
            "15000/15000 [==============================] - 2s 139us/sample - loss: 0.0583 - acc: 0.9862 - val_loss: 0.3973 - val_acc: 0.8717\n",
            "Epoch 14/40\n",
            "15000/15000 [==============================] - 2s 128us/sample - loss: 0.0495 - acc: 0.9895 - val_loss: 0.4261 - val_acc: 0.8736\n",
            "Epoch 15/40\n",
            "15000/15000 [==============================] - 2s 122us/sample - loss: 0.0419 - acc: 0.9929 - val_loss: 0.4417 - val_acc: 0.8727\n",
            "Epoch 16/40\n",
            "15000/15000 [==============================] - 2s 125us/sample - loss: 0.0366 - acc: 0.9937 - val_loss: 0.4633 - val_acc: 0.8708\n",
            "Epoch 17/40\n",
            "15000/15000 [==============================] - 2s 132us/sample - loss: 0.0313 - acc: 0.9952 - val_loss: 0.4794 - val_acc: 0.8703\n",
            "Epoch 18/40\n",
            "15000/15000 [==============================] - 2s 133us/sample - loss: 0.0270 - acc: 0.9960 - val_loss: 0.5096 - val_acc: 0.8690\n",
            "Epoch 19/40\n",
            "15000/15000 [==============================] - 2s 128us/sample - loss: 0.0226 - acc: 0.9967 - val_loss: 0.5380 - val_acc: 0.8664\n",
            "Epoch 20/40\n",
            "15000/15000 [==============================] - 2s 138us/sample - loss: 0.0189 - acc: 0.9977 - val_loss: 0.5977 - val_acc: 0.8646\n",
            "Epoch 21/40\n",
            "15000/15000 [==============================] - 2s 134us/sample - loss: 0.0150 - acc: 0.9982 - val_loss: 0.5951 - val_acc: 0.8643\n",
            "Epoch 22/40\n",
            "15000/15000 [==============================] - 2s 131us/sample - loss: 0.0120 - acc: 0.9984 - val_loss: 0.6238 - val_acc: 0.8628\n",
            "Epoch 23/40\n",
            "15000/15000 [==============================] - 2s 127us/sample - loss: 0.0097 - acc: 0.9991 - val_loss: 0.6689 - val_acc: 0.8636\n",
            "Epoch 24/40\n",
            "15000/15000 [==============================] - 2s 128us/sample - loss: 0.0081 - acc: 0.9992 - val_loss: 0.6872 - val_acc: 0.8612\n",
            "Epoch 25/40\n",
            "15000/15000 [==============================] - 2s 130us/sample - loss: 0.0065 - acc: 0.9994 - val_loss: 0.7545 - val_acc: 0.8592\n",
            "Epoch 26/40\n",
            "15000/15000 [==============================] - 2s 136us/sample - loss: 0.0055 - acc: 0.9995 - val_loss: 0.7433 - val_acc: 0.8599\n",
            "Epoch 27/40\n",
            "15000/15000 [==============================] - 2s 132us/sample - loss: 0.0039 - acc: 0.9997 - val_loss: 0.7815 - val_acc: 0.8583\n",
            "Epoch 28/40\n",
            "15000/15000 [==============================] - 2s 131us/sample - loss: 0.0028 - acc: 0.9998 - val_loss: 0.8131 - val_acc: 0.8593\n",
            "Epoch 29/40\n",
            "15000/15000 [==============================] - 2s 131us/sample - loss: 0.0022 - acc: 0.9999 - val_loss: 0.8455 - val_acc: 0.8585\n",
            "Epoch 30/40\n",
            "15000/15000 [==============================] - 2s 132us/sample - loss: 0.0018 - acc: 0.9999 - val_loss: 0.8737 - val_acc: 0.8587\n",
            "Epoch 31/40\n",
            "15000/15000 [==============================] - 2s 133us/sample - loss: 0.0017 - acc: 0.9999 - val_loss: 0.8941 - val_acc: 0.8571\n",
            "Epoch 32/40\n",
            "15000/15000 [==============================] - 2s 133us/sample - loss: 0.0017 - acc: 0.9999 - val_loss: 0.9371 - val_acc: 0.8567\n",
            "Epoch 33/40\n",
            "15000/15000 [==============================] - 2s 132us/sample - loss: 0.0011 - acc: 0.9999 - val_loss: 0.9486 - val_acc: 0.8566\n",
            "Epoch 34/40\n",
            "15000/15000 [==============================] - 2s 135us/sample - loss: 8.5385e-04 - acc: 0.9999 - val_loss: 0.9866 - val_acc: 0.8567\n",
            "Epoch 35/40\n",
            "15000/15000 [==============================] - 2s 136us/sample - loss: 7.7659e-04 - acc: 0.9999 - val_loss: 1.0058 - val_acc: 0.8578\n",
            "Epoch 36/40\n",
            "15000/15000 [==============================] - 2s 126us/sample - loss: 6.4655e-04 - acc: 0.9999 - val_loss: 1.0277 - val_acc: 0.8566\n",
            "Epoch 37/40\n",
            "15000/15000 [==============================] - 2s 127us/sample - loss: 5.7722e-04 - acc: 0.9999 - val_loss: 1.0516 - val_acc: 0.8559\n",
            "Epoch 38/40\n",
            "15000/15000 [==============================] - 2s 129us/sample - loss: 5.3648e-04 - acc: 1.0000 - val_loss: 1.0770 - val_acc: 0.8548\n",
            "Epoch 39/40\n",
            "15000/15000 [==============================] - 2s 135us/sample - loss: 4.8458e-04 - acc: 1.0000 - val_loss: 1.0969 - val_acc: 0.8554\n",
            "Epoch 40/40\n",
            "15000/15000 [==============================] - 2s 132us/sample - loss: 3.1314e-04 - acc: 1.0000 - val_loss: 1.1014 - val_acc: 0.8537\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f705ea7ce80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUjyC-rmWG7b",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siNn-DpsWHF0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ab801d07-488f-4f04-c951-68670b8672bd"
      },
      "source": [
        "loss, accuracy = model.evaluate(test_data, test_labels)\n",
        "print(f'Test Loss : {loss}'\n",
        "      f'\\nTest Accuracy : {accuracy}')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 1s 44us/sample - loss: 1.1849 - acc: 0.8402\n",
            "Test Loss : 1.184898285342455\n",
            "Test Accuracy : 0.8401600122451782\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Z4lvEu_ZZjA",
        "colab_type": "text"
      },
      "source": [
        "## Save"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoYymqqAZZrm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('movie_reviews.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hssc8WluXXmx",
        "colab_type": "text"
      },
      "source": [
        "# Predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obNlXvMPbBTD",
        "colab_type": "text"
      },
      "source": [
        "## Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgLA_sRzXX0f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.models.load_model('movie_reviews.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LN8caZ6zbHRG",
        "colab_type": "text"
      },
      "source": [
        "## Pre-process input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fus2jWGLdPWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode review\n",
        "def encode_review(review):\n",
        "  encoded = [1]\n",
        "  for word in review:\n",
        "    word = word.lower()\n",
        "    if word in word_index:\n",
        "      encoded.append(word_index[word])\n",
        "    else:\n",
        "      encoded.append(2)\n",
        "  encoded = keras.preprocessing.sequence.pad_sequences([encoded], \n",
        "                                                        value=word_index[\"<PAD>\"],\n",
        "                                                        padding='post',\n",
        "                                                        maxlen=256)\n",
        "  return encoded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHnaiva6bGr2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_review = \"This movie is horrible, i do not know how would the story writer not relate the murder to one of the most infamous mystery\"\n",
        "test_review = \"Good\"\n",
        "\n",
        "# Remove punctutions\n",
        "test_review = test_review.replace(',', '')\n",
        "\n",
        "# Encode review\n",
        "encoded_test_review = encode_review(test_review)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbklaXdLbQ4g",
        "colab_type": "text"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBaDyZxHbPXK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "4b3d3078-0cbd-4da6-a33d-f1400860959e"
      },
      "source": [
        "predict = model.predict([encoded_test_review])\n",
        "print(f'\\n\\nReview : {test_review}')\n",
        "print(f'Prediction : {predict[0]}')"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Review : Good\n",
            "Prediction : [0.58670723]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}